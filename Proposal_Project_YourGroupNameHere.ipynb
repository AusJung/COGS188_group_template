{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Anvita Suresh\n",
    "- Austin Jung\n",
    "- Aarohi Zade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "The goal of our project is to develop an AI agent that is able to beat the game of PacMan autonomously. The agent will be responsible for navigating through a provided maze with the goal of optimizing the amount of pellets collected while avoiding the ghosts. The data that we would use would be the environment of the game including the layout of the maze, pellets that represent the rewards of the game, and more. More specifically, we will be using OpenAI Gym to provide a simulated training environment for our project. We will employ AI algorithms to train the AI agent to make decisions based on different game states. The chosen algorithm should minimize the time spent playing the game and avoid terminating the game (avoiding colliding with ghosts). We will measure the success of the AI agent during the game based on the following metrics: speed of completion, wins and losses, and number of pellets collected if lost. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Pac-Man is a retro video game where the goal is to navigate through a maze-like environment, while collecting pellets for points and evading the enemy ghosts. Since the creation of the game, many people have tried their hardest to collect all of the pellets the fastest, and in recent years, this retro game has become a playground to test different AI algorithms.\n",
    "\n",
    "Various AI algorithms have been tested on the original retro arcade, and some researchers [<sup>[1]</sup>](#swetha). have determined A* search is the optimal solution. Although the article[^1] explores many of the different algorithms, it does not delve into the experimental setups or real-time feasibility. Rather, it reads as more like explaining the optimal solutions to navigating the map.\n",
    "\n",
    "Another group of researchers[<sup>[2]</sup>](#pepels) explored the effectiveness of the Monte Carlo Search Tree when controlling Ms. Pac-Man, particularly when working in real time. The article[<sup>[2]</sup>](#pepels) specifically focused on real-time strategies, specifically using < 40 ms decision making to simulate a real game, and determined that using this algorithm created a strong competitive agent in gathering points.\n",
    "\n",
    "Using the OpenAi Gym[<sup>[3]</sup>](#gupta), this blogger showed how to set up an environment to instruct the agent, using a random search. Although Gupta’s work primarily focuses on the random search rather than AI, it serves as a valuable resource in setting up the environment to work on implementing our own algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Our team’s objective is to implement an AI algorithm taught in class, and tune it to the retro arcade game Ms. Pac-Man. We want the algorithm to control the agent Ms. Pac-Man, which will evade the ghosts and collect the pellets scattered around the map.\n",
    "\n",
    "- Initial State: The map with all of the pellets in position, Ms. Pac-Man at the starting position (centered horizontally and slightly shifted down vertically), and all of the ghosts in the enclosure.\n",
    "- Players: Only 1 player, which is Ms. Pac-Man.\n",
    "- Actions: At every cell, the possible legal moves are going left, right, up, down, and no action. Even when there is a wall at the potential move, the action of Ms. Pac-Man will still turn towards that direction.\n",
    "- Result: The new state of the map, which typically consists of Ms. Pac-Man facing a new position and/or moving along the directed path, along with the removal of pellets from the new cell Ms. Pac-Man is on. Finally, this also results in any changes the random actions of the ghosts have.\n",
    "- Terminal Test: The game ends (reaches terminal state) when either all the pellets have been collected or when the ghosts reach pacman.\n",
    "- Utility: The final outcome will be the total number of pellets collected. So the lower the score, the less pellets that were collected before death, with the maximum score being that all pellets are collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In order to achieve our goal of maximizing our AI agent’s performance in the game of Pacman, we intend to explore a few algorithms that are discussed in class, namely, the A*, Monte Carlo Search Tree, and Backtracking algorithms. Upon implementing each of these algorithms, we will evaluate based on a few metrics such as speed of completion and win/loss ratio to find the optimal policy for the game, which we will establish as our solution. The A* algorithm is a node search procedure that can be useful to minimize a particular cost based on a certain heuristic of success, which could be helpful in optimizing the agent’s decisions. Examples of heuristics we might employ include maximizing distance to the nearest ghost or minimizing the distance to the nearest power-up. Monte Carlo Search Tree (MCST) is a heuristic search procedure that is particularly useful when the search space is more complex. We can use MCTS for our Pacman agent to predict the potential outcomes of moving in different directions, considering the actions of ghosts whose positions at any given time are not fully known. By simulating multiple possible scenarios and evaluating their outcomes, Pacman can make informed decisions to maximize its chances of survival, leading to a successful policy. Lastly, the Backtracking technique explores all possible solutions by following different options and backtracking upon failure. Backtracking would allow the agent to explore different combinations of travel through the maze, as well as different sequences of power-ups or interactions with ghosts. This technique could help find the best strategies possible for navigating the space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "In order to evaluate the performance of our AI agent in playing PacMan, we will use several key metrics to measure and quantify its effectiveness. Firstly, we will consider the speed of completion. A faster completion time indicates that the agent has been trained properly and is more efficient.. We will also track the agent's win-loss ratio, which reflects its ability to successfully complete the game by avoiding termination (colliding with ghosts). If the agent is able to demonstrate a high win to loss ratio, we can prove the agent's skill in evading ghosts and completing the game. Lastly, we will monitor the number of pellets collected if the agent loses. We want to evaluate the agent's performance in maximizing its rewards even if it is unable to complete the game as desired. By evaluating these metrics comprehensively, we can assess the overall proficiency of our AI agent in mastering the game of PacMan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We refer to the Data Science Ethics Checklist[<sup>[4]</sup>](#deon) provided by Deon to ensure that we keep ethical and privacy considerations in mind while designing and developing our project. Our project does not feature any data collection, thus, we do not need to worry about associated risks with collection or data storage. We additionally do not foresee any ethical or privacy risks associated with the Modeling or Analysis sections of the checklist. However, a significant unintended consequence we foresee with the use of our project is through using it to cheat. For example, a user might use the results from our project to artificially set a high score record at an arcade to win tickets, or a speedrunning games website. Upon implementation, in order to prevent unethical abuse of our project, we intend to put guards in place that would prevent our interface from being exploited or fabricated in an external environment such as an arcade or speedrunning website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the expectations of our group, we mainly expect each other to be present at the weekly meetings and contribute ideas regularly. We also want everyone to be responsive to group messages and reply whenever they are able to. If we assign tasks to complete by ourselves, everyone should complete them before the deadline; if one of us cannot complete the task assigned to us, we should let the rest of the team know we can’t complete it. Overall, we expect everyone to have good communication and to stay involved in all aspects of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 4/26  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 5/1  |  10 AM |  Do background research on topic  | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 5/7  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets   | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 5/14  | 6 PM  | Import & Wrangle Data ,do some EDA  | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 5/21  | 12 PM  | Finalize wrangling/EDA; Begin programming for project  | Discuss/edit project code; Complete project |\n",
    "| 5/29  | 12 PM  | Complete analysis; Draft results/conclusion/discussion| Discuss/edit full project |\n",
    "| 6/11  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"swetha\"></a>1.[^](#swetha): Swetha, P, Sowjanya, A.M.(Sept, 2022)  AI Algorithms for PacMan. *International Journal of Creative Research Thoughts*. https://www.ijcrt.org/papers/IJCRT2209015.pdf<br> \n",
    "\n",
    "<a name=\"pepels\"></a>2.[^](#pepels): Pepels, M. H. M. Winands and M. Lanctot. (Sept. 2014) Real-Time Monte Carlo Tree Search in Ms Pac-Man. *IEEE Transactions on Computational Intelligence and AI in Games, vol. 6, no. 3, pp. 245-257*. https://ieeexplore.ieee.org/abstract/document/6731713<br>\n",
    "\n",
    "<a name=\"gupta\"></a>3.[^](#gupta): Gupta, S.(5 June, 2021) The OpenAI Gym. https://shirsho-12.github.io/blog/rl_gym/<br>\n",
    "\n",
    "<a name=\"deon\"></a>4.[^](#deon): https://deon.drivendata.org/<br>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
